#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»çˆ¬è™«è„šæœ¬ - é›†æˆæ‰€æœ‰åŠŸèƒ½çš„ç»Ÿä¸€å…¥å£
åŒ…å«ï¼šæ•°æ®çˆ¬å–ã€éªŒè¯ã€æ¸…ç†ã€ä¿®å¤ã€æ–‡æ¡£ç”Ÿæˆ
"""

import requests
import re
import json
import time
import logging
from datetime import datetime
from typing import Set, List, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MirrorCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.timeout = 20
        self.github_mirrors = set()
        self.docker_mirrors = set()

        # æ•°æ®æºé…ç½®
        self.github_repos = [
            "hunshcn/gh-proxy",
            "XIU2/TrackersListCollection",
            "521xueweihan/GitHub520",
            "fhefh2015/Fast-GitHub",
            "RC1844/FastGithub",
            "dotnetcore/FastGithub",
            "dongyubin/DockerHub"
        ]

        # é¢„è®¾çš„å·²çŸ¥é•œåƒ
        self.known_github_mirrors = {
            "https://gh-proxy.com",
            "https://ghfast.top",
            "https://hub.gitmirror.com",
            "https://github.moeyy.xyz",
            "https://gh.ddlc.top",
            "https://gh.xmly.dev",
            "https://ghps.cc",
            "https://git.886.be",
            "https://github.abskoop.workers.dev",
            "https://ghproxy.net",
            "https://gh.con.sh",
            "https://cors.isteed.cc",
            "https://ghproxy.fsou.cc",
            "https://ghproxy.1888866.xyz",
            "https://fastgit.org",
        }

        self.known_docker_mirrors = {
            "docker.m.daocloud.io",
            "registry.cn-hangzhou.aliyuncs.com",
            "registry.cn-shanghai.aliyuncs.com",
            "registry.cn-beijing.aliyuncs.com",
            "registry.cn-shenzhen.aliyuncs.com",
            "ccr.ccs.tencentyun.com",
            "hub-mirror.c.163.com",
            "mirror.baidubce.com",
            "registry.docker-cn.com",
            "docker.mirrors.ustc.edu.cn",
            "reg-mirror.qiniu.com",
            "registry.cn-qingdao.aliyuncs.com",
            "registry.cn-zhangjiakou.aliyuncs.com"
        }

    def fetch_content(self, url: str) -> str:
        """è·å–ç½‘é¡µå†…å®¹"""
        try:
            logger.info(f"æ­£åœ¨è·å–: {url}")
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            return response.text
        except Exception as e:
            logger.error(f"è·å– {url} å¤±è´¥: {e}")
            return ""

    def extract_github_mirrors(self, content: str) -> Set[str]:
        """ä»å†…å®¹ä¸­æå– GitHub é•œåƒåœ°å€"""
        mirrors = set()

        # GitHub é•œåƒæ¨¡å¼
        patterns = [
            r'https://[^/\s]*(?:gh|github|proxy|mirror|fast)[^/\s]*\.[^/\s]+',
            r'https://[^/\s]+\.(?:workers\.dev|cf|vercel\.app|herokuapp\.com|netlify\.app)',
            r'https://(?:gh-proxy|ghfast|ghproxy|ghps)\.[^/\s]+',
            r'https://hub\.gitmirror\.com',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                clean_url = match.strip().rstrip('/')
                if self.is_valid_github_mirror(clean_url):
                    mirrors.add(clean_url)

        return mirrors

    def extract_docker_mirrors(self, content: str) -> Set[str]:
        """ä»å†…å®¹ä¸­æå– Docker é•œåƒåœ°å€"""
        mirrors = set()

        patterns = [
            r'[^/\s]*\.(?:aliyuncs\.com|tencentcloudcr\.com)',
            r'docker\.m\.daocloud\.io',
            r'ccr\.ccs\.tencentyun\.com',
            r'hub-mirror\.c\.163\.com',
            r'mirror\.baidubce\.com',
            r'registry\.docker-cn\.com',
            r'docker\.mirrors\.ustc\.edu\.cn',
            r'reg-mirror\.qiniu\.com',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                clean_url = match.strip().rstrip('/')
                if self.is_valid_docker_mirror(clean_url):
                    mirrors.add(clean_url)

        return mirrors

    def is_valid_github_mirror(self, url: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ GitHub é•œåƒ"""
        if not url.startswith('https://'):
            return False

        # æ’é™¤æ˜æ˜¾ä¸æ˜¯é•œåƒçš„åŸŸå
        exclude_patterns = [
            r'github\.com', r'raw\.githubusercontent\.com', r'api\.github\.com',
            r'img\.shields\.io', r'cdn\.jsdelivr\.net', r'docs\.docker\.com',
            r'blog\.', r'cdn\.', r'web\.archive\.org', r'\.png$', r'\.jpg$', r'\.svg'
        ]

        for pattern in exclude_patterns:
            if re.search(pattern, url, re.IGNORECASE):
                return False

        return len(url) > 10

    def is_valid_docker_mirror(self, url: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ Docker é•œåƒ"""
        if not url or '.' not in url:
            return False

        # æ’é™¤æ— æ•ˆçš„æ¨¡å¼
        if '<' in url or '>' in url or 'your_code' in url:
            return False

        valid_patterns = [
            r'\.aliyuncs\.com$', r'\.tencentcloudcr\.com$', r'docker\.m\.daocloud\.io$',
            r'ccr\.ccs\.tencentyun\.com$', r'hub-mirror\.c\.163\.com$',
            r'mirror\.baidubce\.com$', r'registry\.docker-cn\.com$',
            r'docker\.mirrors\.ustc\.edu\.cn$', r'reg-mirror\.qiniu\.com$'
        ]

        return any(re.search(pattern, url) for pattern in valid_patterns)

    def crawl_github_repos(self):
        """çˆ¬å– GitHub ä»“åº“"""
        logger.info("ğŸ” å¼€å§‹çˆ¬å– GitHub ä»“åº“...")

        for repo in self.github_repos:
            try:
                # å°è¯• master åˆ†æ”¯
                readme_url = f"https://raw.githubusercontent.com/{repo}/master/README.md"
                content = self.fetch_content(readme_url)

                if not content:
                    # å°è¯• main åˆ†æ”¯
                    readme_url = f"https://raw.githubusercontent.com/{repo}/main/README.md"
                    content = self.fetch_content(readme_url)

                if content:
                    github_mirrors = self.extract_github_mirrors(content)
                    self.github_mirrors.update(github_mirrors)

                    docker_mirrors = self.extract_docker_mirrors(content)
                    self.docker_mirrors.update(docker_mirrors)

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

            except Exception as e:
                logger.error(f"çˆ¬å–ä»“åº“ {repo} å¤±è´¥: {e}")

    def add_known_mirrors(self):
        """æ·»åŠ å·²çŸ¥çš„é•œåƒåœ°å€"""
        logger.info("ğŸ“‹ æ·»åŠ å·²çŸ¥é•œåƒåœ°å€...")
        self.github_mirrors.update(self.known_github_mirrors)
        self.docker_mirrors.update(self.known_docker_mirrors)

    def test_github_mirror_content(self, mirror_url: str) -> dict:
        """æµ‹è¯• GitHub é•œåƒçš„å†…å®¹ä¸‹è½½åŠŸèƒ½"""
        test_file_url = "https://gist.githubusercontent.com/weekoo2025/7a8bcb034d5d223384101b8c4773089a/raw/all.txt"
        test_url = f"{mirror_url}/{test_file_url}"

        result = {
            'url': mirror_url,
            'status': 'unknown',
            'response_time': None,
            'content_valid': False
        }

        try:
            start_time = time.time()
            response = self.session.get(test_url, timeout=self.timeout)
            response_time = time.time() - start_time

            result['response_time'] = round(response_time * 1000, 2)

            if response.status_code == 200:
                content = response.text.strip()

                # éªŒè¯å†…å®¹æœ‰æ•ˆæ€§
                if (len(content) > 50 and
                    ('http' in content.lower() or 'docker' in content.lower() or
                     'registry' in content.lower() or 'mirror' in content.lower())):
                    result['status'] = 'available'
                    result['content_valid'] = True
                else:
                    result['status'] = 'content_invalid'
            else:
                result['status'] = 'http_error'

        except Exception as e:
            result['status'] = 'error'

        return result

    def validate_github_mirrors(self):
        """éªŒè¯ GitHub é•œåƒçš„å¯ç”¨æ€§"""
        logger.info("ğŸ§ª å¼€å§‹éªŒè¯ GitHub é•œåƒ...")

        valid_mirrors = []

        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_url = {executor.submit(self.test_github_mirror_content, url): url
                           for url in self.github_mirrors}

            for future in as_completed(future_to_url):
                result = future.result()

                if result['content_valid']:
                    valid_mirrors.append(result['url'])
                    logger.info(f"âœ… {result['url']} ({result['response_time']}ms)")
                else:
                    logger.warning(f"âŒ {result['url']} - {result['status']}")

        self.github_mirrors = set(valid_mirrors)
        logger.info(f"ğŸ“Š GitHub é•œåƒéªŒè¯å®Œæˆ: {len(valid_mirrors)} ä¸ªå¯ç”¨")

    def generate_mirrors_json(self):
        """ç”Ÿæˆ mirrors.json æ–‡ä»¶"""
        logger.info("ğŸ“„ ç”Ÿæˆ mirrors.json...")

        # æ¸…ç† Docker é•œåƒæ ¼å¼
        clean_docker_mirrors = []
        for url in self.docker_mirrors:
            clean_url = url.replace('https://', '').replace('http://', '')
            clean_docker_mirrors.append(clean_url)

        data = {
            'update_time': datetime.now().isoformat(),
            'github_mirrors': {
                'count': len(self.github_mirrors),
                'urls': sorted(list(self.github_mirrors))
            },
            'docker_mirrors': {
                'count': len(clean_docker_mirrors),
                'urls': sorted(list(set(clean_docker_mirrors)))
            }
        }

        with open('mirrors.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… mirrors.json ç”Ÿæˆå®Œæˆ")
        logger.info(f"ğŸ“Š GitHub é•œåƒ: {len(self.github_mirrors)} ä¸ª")
        logger.info(f"ğŸ“Š Docker é•œåƒ: {len(clean_docker_mirrors)} ä¸ª")

    def generate_readme(self):
        """ç”Ÿæˆ README.md æ–‡ä»¶"""
        logger.info("ğŸ“ ç”Ÿæˆ README.md...")

        try:
            with open('mirrors.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
        except:
            logger.error("æ— æ³•è¯»å– mirrors.json")
            return

        github_mirrors = data['github_mirrors']['urls']
        docker_mirrors = data['docker_mirrors']['urls']
        update_time = data['update_time']

        # æ ¼å¼åŒ–æ›´æ–°æ—¶é—´
        try:
            dt = datetime.fromisoformat(update_time.replace('Z', '+00:00'))
            formatted_time = dt.strftime('%Y-%m-%d %H:%M:%S')
        except:
            formatted_time = update_time

        readme_content = f"""# ğŸš€ ä¸­å›½åŒº GitHub å’Œ Docker åŠ é€Ÿé•œåƒ

æœ¬ä»“åº“è‡ªåŠ¨æ”¶é›†å’Œæ›´æ–°é€‚ç”¨äºä¸­å›½åŒºçš„ GitHub æ–‡ä»¶åŠ é€Ÿå’Œ Docker é•œåƒåŠ é€Ÿåœ°å€ã€‚

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æœ€åæ›´æ–°**: {formatted_time}
- **GitHub é•œåƒæ•°é‡**: {len(github_mirrors)}
- **Docker é•œåƒæ•°é‡**: {len(docker_mirrors)}

## ğŸ”¥ GitHub æ–‡ä»¶åŠ é€Ÿ

ä»¥ä¸‹æ˜¯ç»è¿‡éªŒè¯çš„ GitHub æ–‡ä»¶åŠ é€Ÿé•œåƒåœ°å€ï¼š

"""

        for mirror in github_mirrors:
            readme_content += f"- {mirror}\n"

        readme_content += f"""
### ğŸ“– ä½¿ç”¨æ–¹æ³•

å°†åŸå§‹çš„ GitHub æ–‡ä»¶é“¾æ¥å‰ç¼€æ›¿æ¢ä¸ºé•œåƒåœ°å€ï¼š

```bash
# åŸå§‹é“¾æ¥
https://github.com/user/repo/releases/download/v1.0/file.zip

# åŠ é€Ÿé“¾æ¥
https://é•œåƒåœ°å€/https://github.com/user/repo/releases/download/v1.0/file.zip
```

## ğŸ³ Docker é•œåƒåŠ é€Ÿ

ä»¥ä¸‹æ˜¯æ”¶é›†åˆ°çš„ Docker é•œåƒåŠ é€Ÿåœ°å€ï¼š

"""

        for mirror in docker_mirrors:
            readme_content += f"- {mirror}\n"

        readme_content += f"""
### ğŸ“– ä½¿ç”¨æ–¹æ³•

é…ç½® Docker é•œåƒåŠ é€Ÿå™¨ï¼š

```bash
# åˆ›å»ºæˆ–ç¼–è¾‘ /etc/docker/daemon.json
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{{
  "registry-mirrors": [
    "https://docker.m.daocloud.io",
    "https://registry.cn-hangzhou.aliyuncs.com"
  ]
}}
EOF

# é‡å¯ Docker æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl restart docker
```

## ğŸ“ æ•°æ®æ¥æº

é•œåƒåœ°å€æ¥æºäºä»¥ä¸‹é¡¹ç›®ï¼š

- [hunshcn/gh-proxy](https://github.com/hunshcn/gh-proxy)
- [XIU2/TrackersListCollection](https://github.com/XIU2/TrackersListCollection)
- [521xueweihan/GitHub520](https://github.com/521xueweihan/GitHub520)
- [dongyubin/DockerHub](https://github.com/dongyubin/DockerHub)

## ğŸ”„ è‡ªåŠ¨æ›´æ–°

æœ¬ä»“åº“é€šè¿‡ GitHub Actions æ¯å¤©è‡ªåŠ¨æ›´æ–°é•œåƒåœ°å€åˆ—è¡¨ã€‚

## âš ï¸ å…è´£å£°æ˜

- æœ¬é¡¹ç›®ä»…æ”¶é›†å…¬å¼€å¯ç”¨çš„é•œåƒåœ°å€
- è¯·æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„é•œåƒåœ°å€
- ä½¿ç”¨é•œåƒæœåŠ¡æ—¶è¯·éµå®ˆç›¸å…³æœåŠ¡æ¡æ¬¾

---

**æœ€åæ›´æ–°æ—¶é—´**: {formatted_time}
"""

        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme_content)

        logger.info("âœ… README.md ç”Ÿæˆå®Œæˆ")

    def run(self):
        """è¿è¡Œå®Œæ•´çš„çˆ¬è™«æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œé•œåƒçˆ¬è™«...")
        start_time = time.time()

        # æ­¥éª¤1: æ·»åŠ å·²çŸ¥é•œåƒ
        self.add_known_mirrors()

        # æ­¥éª¤2: çˆ¬å–ç½‘ç»œæ•°æ®
        self.crawl_github_repos()

        # æ­¥éª¤3: éªŒè¯ GitHub é•œåƒ
        self.validate_github_mirrors()

        # æ­¥éª¤4: ç”Ÿæˆæ•°æ®æ–‡ä»¶
        self.generate_mirrors_json()

        # æ­¥éª¤5: ç”Ÿæˆ README
        self.generate_readme()

        end_time = time.time()
        logger.info(f"âœ… çˆ¬è™«è¿è¡Œå®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’")

def main():
    """ä¸»å‡½æ•°"""
    crawler = MirrorCrawler()
    crawler.run()

if __name__ == "__main__":
    main()
